# Grafana Alert Rules for .NET Memory App Advanced Health Checks
# Import these into Grafana Alerting

groups:
  - name: dotnet-memory-app-health
    interval: 30s
    rules:
      
      # Critical Health Alerts
      - alert: DotNetAppUnhealthy
        expr: min(dotnet_health_check_status) < 0.5
        for: 1m
        labels:
          severity: critical
          service: dotnet-memory-app
          component: health-check
        annotations:
          summary: ".NET application is unhealthy"
          description: "Overall health status is {{ $value }} for {{ $labels.instance }}"
          runbook_url: "https://your-docs.com/runbooks/dotnet-app-unhealthy"
          
      - alert: DotNetMemoryHealthCritical
        expr: dotnet_health_check_status{check_name="memory"} < 0.5
        for: 2m
        labels:
          severity: critical
          service: dotnet-memory-app
          component: memory
        annotations:
          summary: "Critical memory health issues detected"
          description: "Memory health check status is {{ $value }} for {{ $labels.instance }}"
          
      # Memory Pressure Alerts
      - alert: DotNetHighMemoryPressure
        expr: dotnet_gc_memory_pressure_percent > 85
        for: 2m
        labels:
          severity: warning
          service: dotnet-memory-app
          component: gc
        annotations:
          summary: "High GC memory pressure detected"
          description: "Memory pressure is {{ $value }}% (threshold: 85%) for {{ $labels.instance }}"
          
      - alert: DotNetCriticalMemoryPressure
        expr: dotnet_gc_memory_pressure_percent > 95
        for: 30s
        labels:
          severity: critical
          service: dotnet-memory-app
          component: gc
        annotations:
          summary: "Critical GC memory pressure - OOM risk"
          description: "Memory pressure is {{ $value }}% (critical: 95%) for {{ $labels.instance }}"
          
      # Container Resource Alerts
      - alert: DotNetContainerMemoryHigh
        expr: dotnet_container_utilization_percent > 85
        for: 3m
        labels:
          severity: warning
          service: dotnet-memory-app
          component: container
        annotations:
          summary: "High container memory utilization"
          description: "Container memory utilization is {{ $value }}% for {{ $labels.instance }}"
          
      - alert: DotNetContainerMemoryCritical
        expr: dotnet_container_utilization_percent > 95
        for: 1m
        labels:
          severity: critical
          service: dotnet-memory-app
          component: container
        annotations:
          summary: "Critical container memory utilization - OOMKill risk"
          description: "Container memory utilization is {{ $value }}% for {{ $labels.instance }}"
          
      # OutOfMemoryException Alerts
      - alert: DotNetOutOfMemoryExceptions
        expr: increase(dotnet_out_of_memory_exceptions_total[5m]) > 0
        for: 0m
        labels:
          severity: warning
          service: dotnet-memory-app
          component: gc
        annotations:
          summary: "OutOfMemoryExceptions occurring"
          description: "{{ $value }} OutOfMemoryExceptions in the last 5 minutes for {{ $labels.instance }}"
          
      - alert: DotNetFrequentOOMs
        expr: rate(dotnet_out_of_memory_exceptions_total[5m]) > 0.1
        for: 2m
        labels:
          severity: critical
          service: dotnet-memory-app
          component: gc
        annotations:
          summary: "Frequent OutOfMemoryExceptions detected"
          description: "OOM rate is {{ $value }}/sec for {{ $labels.instance }}"
          
      # GC Performance Alerts
      - alert: DotNetHighGCActivity
        expr: rate(dotnet_gc_collections_total{generation="2"}[5m]) > 0.5
        for: 3m
        labels:
          severity: warning
          service: dotnet-memory-app
          component: gc
        annotations:
          summary: "High Gen2 GC activity detected"
          description: "Gen2 GC rate is {{ $value }}/sec for {{ $labels.instance }}"
          
      - alert: DotNetGCHealthDegraded
        expr: dotnet_health_check_status{check_name="gc"} < 1
        for: 5m
        labels:
          severity: warning
          service: dotnet-memory-app
          component: gc
        annotations:
          summary: "GC health is degraded"
          description: "GC health status is {{ $value }} for {{ $labels.instance }}"
          
      # Health Check Performance Alerts
      - alert: DotNetSlowHealthChecks
        expr: dotnet_health_check_duration_seconds > 0.1
        for: 2m
        labels:
          severity: warning
          service: dotnet-memory-app
          component: health-check
        annotations:
          summary: "Slow health check performance"
          description: "Health check {{ $labels.check_name }} took {{ $value }}s for {{ $labels.instance }}"
          
      # Application Availability Alerts
      - alert: DotNetAppDown
        expr: up{job="dotnet-memory-app"} == 0
        for: 30s
        labels:
          severity: critical
          service: dotnet-memory-app
          component: application
        annotations:
          summary: ".NET application is down"
          description: "Application metrics endpoint is not reachable for {{ $labels.instance }}"
          
      # Pod Scaling Alerts (HPA related)
      - alert: DotNetPodScalingActive
        expr: changes(kube_deployment_status_replicas{deployment="dotnet-memory-app-advanced-health"}[5m]) > 0
        for: 0m
        labels:
          severity: info
          service: dotnet-memory-app
          component: scaling
        annotations:
          summary: "Pod scaling activity detected"
          description: "Deployment replica count changed for dotnet-memory-app"
          
      - alert: DotNetMaxPodsReached
        expr: kube_deployment_status_replicas{deployment="dotnet-memory-app-advanced-health"} >= 5
        for: 1m
        labels:
          severity: warning
          service: dotnet-memory-app
          component: scaling
        annotations:
          summary: "Maximum pod count reached"
          description: "Deployment has reached maximum replica count of {{ $value }}"

# Notification routing configuration
route:
  group_by: ['alertname', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
  - match:
      severity: critical
    receiver: 'critical-alerts'
    group_wait: 5s
    repeat_interval: 30m
  - match:
      severity: warning
    receiver: 'warning-alerts'
    repeat_interval: 2h
  - match:
      severity: info
    receiver: 'info-alerts'
    repeat_interval: 12h

receivers:
- name: 'web.hook'
  webhook_configs:
  - url: 'http://127.0.0.1:5001/'
    
- name: 'critical-alerts'
  slack_configs:
  - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    channel: '#alerts-critical'
    title: 'üö® Critical Alert: {{ .GroupLabels.alertname }}'
    text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
    color: 'danger'
    
- name: 'warning-alerts'
  slack_configs:
  - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    channel: '#alerts-warning'
    title: '‚ö†Ô∏è Warning: {{ .GroupLabels.alertname }}'
    text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
    color: 'warning'
    
- name: 'info-alerts'
  slack_configs:
  - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    channel: '#alerts-info'
    title: '‚ÑπÔ∏è Info: {{ .GroupLabels.alertname }}'
    text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
    color: 'good'
